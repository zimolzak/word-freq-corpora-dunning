{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word frequency differences between two text corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have two books (or other writings). Which words are overrepresented in book *A*, and which are overrepresented in *B*? One way to see is Dunning log likelihood.\n",
    "\n",
    "See: Dunning, T. Accurate Methods for the Statistics of Surprise and Coincidence. *Computational Linguistics* 19, 61–74 (1993).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import math\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def pg2txt(pgnum):\n",
    "    \"\"\"Given a Project Gutenberg number, download & return its text.\"\"\"\n",
    "    s = str(pgnum)\n",
    "    url = 'https://gutenberg.org/files/' + s + '/' + s + '-0.txt'\n",
    "    #      https://gutenberg.org/files/      161/161-0.txt\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    text = data.decode('utf-8')\n",
    "    return(text)\n",
    "\n",
    "SENSE_N = 161    # Project Gutenberg numeric identifiers\n",
    "PRIDE_N = 1342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the actual download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSE = pg2txt(SENSE_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIDE = pg2txt(PRIDE_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut out the Gutenberg preamble and end matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN = 1700\n",
    "END_SENSE = 684300\n",
    "endmatter = len(SENSE) - END_SENSE\n",
    "END_PRIDE = len(PRIDE) - endmatter\n",
    "\n",
    "pc = PRIDE[BEGIN:END_PRIDE]\n",
    "sc = SENSE[BEGIN:END_SENSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change certain punctuation to spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT = \"“”,.?\\\";:-_—!\"  # don't remove apostrophe?  ' and ’\n",
    "SPACES = ' ' * len(PUNCT)\n",
    "table = str.maketrans(PUNCT, SPACES)\n",
    "\n",
    "ps = pc.translate(table).lower().split()\n",
    "ss = sc.translate(table).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define stop words and filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = \"a able about across after all almost also am among an and any are as at be because been but by can cannot could dear did do does either else ever every for from get got had has have he her hers him his how however i if in into is it its just least let like likely may me might most must my neither no nor not of off often on only or other our own rather said say says she should since so some than that the their them then there these they this tis to too twas us wants was we were what when where which while who whom why will with would yet you your\"\n",
    "# https://www.textfixer.com/tutorials/common-english-words.txt\n",
    "swl = stopwords.split() + ['chapter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all(tlist, slist):\n",
    "    for w in slist:\n",
    "        tlist = list(filter(lambda a: a != w, tlist))\n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = filter_all(ps, swl)\n",
    "sf = filter_all(ss, swl)\n",
    "# 3 sec for both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of filtered text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'single',\n",
       " 'man',\n",
       " 'possession',\n",
       " 'good',\n",
       " 'fortune',\n",
       " 'want',\n",
       " 'wife']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf[19:29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count up words in each corpus (longest step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wlist2freqs(wlist):\n",
    "    multiplier = 1000000\n",
    "    denom = len(wlist)\n",
    "    vocab = set(wlist)\n",
    "    fdict = dict()\n",
    "    for w in vocab:\n",
    "        n = wlist.count(w)\n",
    "        fdict[w] = n / denom * multiplier\n",
    "    return(fdict)\n",
    "\n",
    "def wlist2counts(wlist):\n",
    "    \"\"\"Given a text (list of words), return dict where keys are words and values are word counts.\"\"\"\n",
    "    vocab = set(wlist)\n",
    "    fdict = dict()\n",
    "    for w in vocab:\n",
    "        fdict[w] = wlist.count(w)\n",
    "    return(fdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd = wlist2freqs(pf)  # 6 sec\n",
    "# sd = wlist2freqs(sf)\n",
    "pc = wlist2counts(pf)\n",
    "sc = wlist2counts(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy-pasted Dunning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# http://pioneer.chula.ac.th/~awirote/colloc/statmethod1.htm\n",
    "# https://github.com/dhmit/gender_novels/blob/master/gender_novels/analysis/dunning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunning_total(counter1, counter2):\n",
    "    \"\"\"Runs dunning_individual on words shared by both counter objects.\n",
    "    Positive means words in counter_1. Negative means words in counter_2.\n",
    "    The larger the magnitude of the number, the more distinctive that word is in its\n",
    "    respective counter object.\n",
    "    Result is a dict that maps each word to its to results.\n",
    "    Each result dict contains the dunning score.\n",
    "    >>> results['he']\n",
    "    -8.547243830635558\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "\n",
    "    t1 = sum(counter1.values())\n",
    "    t2 = sum(counter2.values())\n",
    "    \n",
    "    dunning_result = {}  # dictionary where results will be returned\n",
    "    for word in counter1:\n",
    "        if word not in counter2:\n",
    "            continue\n",
    "        if counter1[word] + counter2[word] < 10:\n",
    "            continue\n",
    "        dunning_result[word] = dunn_individual_word(t1, t2, counter1[word], counter2[word])\n",
    "\n",
    "    return dunning_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_individual_word(t1, t2, c1, c2):\n",
    "    \"\"\"\n",
    "    Applies dunning log likelihood to compare individual word in two counter objects.\n",
    "    :return: log likelihood\n",
    "    >>> total_words_m_corpus = 8648489\n",
    "    >>> total_words_f_corpus = 8700765\n",
    "    >>> wordcount_female = 1000\n",
    "    >>> wordcount_male = 50\n",
    "    >>> dunn_individual_word(total_words_m_corpus,total_words_f_corpus,wordcount_male,wordcount_female)\n",
    "    -1047.8610274053995\n",
    "    \"\"\"\n",
    "    \n",
    "    Pr_1 = c1 / t1\n",
    "    Pr_2 = c2 / t2\n",
    "    Pr_12 = (c1 + c2) / (t1 + t2)\n",
    "\n",
    "    d = 2 * (c1 * math.log(Pr_1 / Pr_12) + c2 * math.log(Pr_2 / Pr_12))\n",
    "\n",
    "    if c1 * math.log(Pr_1 / Pr_12) >= 0:\n",
    "        return d\n",
    "    else:\n",
    "        return -1 * d\n",
    "\n",
    "    # p = 1 - chi2.cdf(abs(dunning_log_likelihood),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dunning_total(pc, sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit to the very most significant, and display them sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mr': 401.1,\n",
       " 'aunt': 97.4,\n",
       " 'father': 64.1,\n",
       " 'ball': 41.5,\n",
       " 'william': 41.4,\n",
       " 'mary': 38.9,\n",
       " 'uncle': 34.1,\n",
       " 'mother': -33.8,\n",
       " 'heart': -42.3,\n",
       " 'mrs': -43.4,\n",
       " 'colonel': -46.8,\n",
       " 'body': -56.0,\n",
       " 'thing': -100.9,\n",
       " 'john': -188.0,\n",
       " 'edward': -297.6}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = 30\n",
    "filtered = {}\n",
    "for word in result:\n",
    "    d = result[word]\n",
    "    if d > THRESHOLD or d < (-1 * THRESHOLD):\n",
    "        filtered[word] = round(d,1)\n",
    "\n",
    "# negative means Sense, positive means Pride\n",
    "\n",
    "filtered_sorted = dict(sorted(filtered.items(), key=lambda item: item[1], reverse=True))\n",
    "filtered_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
