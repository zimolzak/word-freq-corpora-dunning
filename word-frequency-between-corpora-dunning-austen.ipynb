{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word frequency differences between two text corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have two books (or other writings). Which words are overrepresented in book *A*, and which are overrepresented in *B*? One way to see is Dunning log likelihood.\n",
    "\n",
    "See: Dunning, T. Accurate Methods for the Statistics of Surprise and Coincidence. *Computational Linguistics* 19, 61–74 (1993).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import math\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def pg2txt(pgnum):\n",
    "    \"\"\"Given a Project Gutenberg number, download & return its text.\"\"\"\n",
    "    s = str(pgnum)\n",
    "    url = 'https://gutenberg.org/files/' + s + '/' + s + '-0.txt'\n",
    "    #      https://gutenberg.org/files/      161/161-0.txt\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read()      # a `bytes` object\n",
    "    text = data.decode('utf-8')\n",
    "    return(text)\n",
    "\n",
    "SENSE_N = 161    # Project Gutenberg numeric identifiers\n",
    "PRIDE_N = 1342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the actual download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSE = pg2txt(SENSE_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIDE = pg2txt(PRIDE_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut out the Gutenberg preamble and end matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEGIN = 1700\n",
    "END_SENSE = 684300\n",
    "endmatter = len(SENSE) - END_SENSE\n",
    "END_PRIDE = len(PRIDE) - endmatter\n",
    "\n",
    "pc = PRIDE[BEGIN:END_PRIDE]\n",
    "sc = SENSE[BEGIN:END_SENSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change certain punctuation to spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT = \"“”,.?\\\";:-_—!\"  # don't remove apostrophe?  ' and ’\n",
    "SPACES = ' ' * len(PUNCT)\n",
    "table = str.maketrans(PUNCT, SPACES)\n",
    "\n",
    "ps = pc.translate(table).lower().split()\n",
    "ss = sc.translate(table).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define stop words and filter them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = \"a able about across after all almost also am among an and any are as at be because been but by can cannot could dear did do does either else ever every for from get got had has have he her hers him his how however i if in into is it its just least let like likely may me might most must my neither no nor not of off often on only or other our own rather said say says she should since so some than that the their them then there these they this tis to too twas us wants was we were what when where which while who whom why will with would yet you your\"\n",
    "# https://www.textfixer.com/tutorials/common-english-words.txt\n",
    "swl = stopwords.split() + ['chapter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_all(tlist, slist):\n",
    "    for w in slist:\n",
    "        tlist = list(filter(lambda a: a != w, tlist))\n",
    "    return tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = filter_all(ps, swl)\n",
    "sf = filter_all(ss, swl)\n",
    "# 3 sec for both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'single',\n",
       " 'man',\n",
       " 'possession',\n",
       " 'good',\n",
       " 'fortune',\n",
       " 'want',\n",
       " 'wife']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf[19:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wlist2freqs(wlist):\n",
    "    multiplier = 1000000\n",
    "    denom = len(wlist)\n",
    "    vocab = set(wlist)\n",
    "    fdict = dict()\n",
    "    for w in vocab:\n",
    "        n = wlist.count(w)\n",
    "        fdict[w] = n / denom * multiplier\n",
    "    return(fdict)\n",
    "\n",
    "def wlist2counts(wlist):\n",
    "    vocab = set(wlist)\n",
    "    fdict = dict()\n",
    "    for w in vocab:\n",
    "        fdict[w] = wlist.count(w)\n",
    "    return(fdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = wlist2freqs(pf)  # 6 sec\n",
    "sd = wlist2freqs(sf)\n",
    "pc = wlist2counts(pf)\n",
    "sc = wlist2counts(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy-pasted Dunning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# http://pioneer.chula.ac.th/~awirote/colloc/statmethod1.htm\n",
    "# https://github.com/dhmit/gender_novels/blob/master/gender_novels/analysis/dunning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunning_total(counter1, counter2, filename_to_pickle=None):\n",
    "    '''\n",
    "    runs dunning_individual on words shared by both counter objects\n",
    "    (-) end of spectrum is words for counter_2\n",
    "    (+) end of spectrum is words for counter_1\n",
    "    the larger the magnitude of the number, the more distinctive that word is in its\n",
    "    respective counter object\n",
    "    use filename_to_pickle to store the result so it only has to be calculated once and can be\n",
    "    used for multiple analyses.\n",
    "    >>> from collections import Counter\n",
    "    >>> female_counter = Counter({'he': 1,  'she': 10, 'and': 10})\n",
    "    >>> male_counter =   Counter({'he': 10, 'she': 1,  'and': 10})\n",
    "    >>> results = dunning_total(female_counter, male_counter)\n",
    "    # Results is a dict that maps from terms to results\n",
    "    # Each result dict contains the dunning score...\n",
    "    >>> results['he']['dunning']\n",
    "    -8.547243830635558\n",
    "    # ... counts for corpora 1 and 2 as well as total count\n",
    "    >>> results['he']['count_total'], results['he']['count_corp1'], results['he']['count_corp2']\n",
    "    (11, 1, 10)\n",
    "    # ... and the same for frequencies\n",
    "    >>> results['he']['freq_total'], results['he']['freq_corp1'], results['he']['freq_corp2']\n",
    "    (0.2619047619047619, 0.047619047619047616, 0.47619047619047616)\n",
    "    :return: dict\n",
    "    '''\n",
    "\n",
    "    total_words_counter1 = 0\n",
    "    total_words_counter2 = 0\n",
    "\n",
    "    #get word total in respective counters\n",
    "    for word1 in counter1:\n",
    "        total_words_counter1 += counter1[word1]\n",
    "    for word2 in  counter2:\n",
    "        total_words_counter2 += counter2[word2]\n",
    "\n",
    "    #dictionary where results will be returned\n",
    "    dunning_result = {}\n",
    "    for word in counter1:\n",
    "        counter1_wordcount = counter1[word]\n",
    "        if word in counter2:\n",
    "            counter2_wordcount = counter2[word]\n",
    "\n",
    "\n",
    "            if counter1_wordcount + counter2_wordcount < 10:\n",
    "                continue\n",
    "\n",
    "            dunning_word = dunn_individual_word( total_words_counter1,  total_words_counter2,\n",
    "                                                 counter1_wordcount,counter2_wordcount)\n",
    "\n",
    "            dunning_result[word] = {\n",
    "                'dunning': dunning_word,\n",
    "                'count_total': counter1_wordcount + counter2_wordcount,\n",
    "                'count_corp1': counter1_wordcount,\n",
    "                'count_corp2': counter2_wordcount,\n",
    "                'freq_total': (counter1_wordcount + counter2_wordcount) / (total_words_counter1 +\n",
    "                                                                           total_words_counter2),\n",
    "                'freq_corp1': counter1_wordcount / total_words_counter1,\n",
    "                'freq_corp2': counter2_wordcount / total_words_counter2\n",
    "            }\n",
    "\n",
    "    if filename_to_pickle:\n",
    "        store_pickle(dunning_result, filename_to_pickle)\n",
    "\n",
    "    return dunning_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_individual_word(total_words_in_corpus_1, total_words_in_corpus_2,\n",
    "                         count_of_word_in_corpus_1,\n",
    "                         count_of_word_in_corpus_2):\n",
    "    '''\n",
    "    applies dunning log likelihood to compare individual word in two counter objects\n",
    "    :param word: desired word to compare\n",
    "    :param m_corpus: c.filter_by_gender('male')\n",
    "    :param f_corpus: c. filter_by_gender('female')\n",
    "    :return: log likelihoods and p value\n",
    "    >>> total_words_m_corpus = 8648489\n",
    "    >>> total_words_f_corpus = 8700765\n",
    "    >>> wordcount_female = 1000\n",
    "    >>> wordcount_male = 50\n",
    "    >>> dunn_individual_word(total_words_m_corpus,total_words_f_corpus,wordcount_male,wordcount_female)\n",
    "    -1047.8610274053995\n",
    "    '''\n",
    "    a = count_of_word_in_corpus_1\n",
    "    b = count_of_word_in_corpus_2\n",
    "    c = total_words_in_corpus_1\n",
    "    d = total_words_in_corpus_2\n",
    "\n",
    "    e1 = c * (a + b) / (c + d)\n",
    "    e2 = d * (a + b) / (c + d)\n",
    "\n",
    "    dunning_log_likelihood = 2 * (a * math.log(a / e1) + b * math.log(b / e2))\n",
    "\n",
    "    if count_of_word_in_corpus_1 * math.log(count_of_word_in_corpus_1 / e1) < 0:\n",
    "        dunning_log_likelihood = -dunning_log_likelihood\n",
    "\n",
    "    p = 1 - chi2.cdf(abs(dunning_log_likelihood),1)\n",
    "\n",
    "    return dunning_log_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mr': 401.5,\n",
       " 'aunt': 96.1,\n",
       " 'father': 62.2,\n",
       " 'william': 41.5,\n",
       " 'ball': 41.5,\n",
       " 'mary': 38.9,\n",
       " 'uncle': 34.3,\n",
       " 'mother': -33.2,\n",
       " 'heart': -40.6,\n",
       " 'mrs': -43.3,\n",
       " 'colonel': -46.8,\n",
       " 'body': -53.3,\n",
       " 'thing': -94.9,\n",
       " 'john': -187.9,\n",
       " 'edward': -283.5}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = dunning_total(pc, sc)\n",
    "THRESHOLD = 30\n",
    "filt = {}\n",
    "for word in result:\n",
    "    wdict = result[word]\n",
    "    d = wdict['dunning']\n",
    "    if d > THRESHOLD or d < (-1 * THRESHOLD):\n",
    "        filt[word] = round(d,1)\n",
    "\n",
    "# negative means Sense, positive means Pride\n",
    "\n",
    "final = dict(sorted(filt.items(), key=lambda item: item[1], reverse=True))\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
